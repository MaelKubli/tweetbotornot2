---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
options(width = 90, digits = 5, scipen = 6,
  datatable.print.topn = 5, datatable.print.nrows = 30)
library(tweetbotornot2)
```

# tweetbotornot2

<!-- badges: start -->
<!-- badges: end -->

{tweetbotornot2} provides an out-of-the-box classifier for detecting Twitter bots that 
is easy to use, volume-friendly (classify over two hundred thousands accounts per day),
accurate (see paper), robust and customizable (update the model with new or user-defined training data),
and explainable (view feature contributions behind each estimated probability).
    
## Installation

You can install the released version of tweetbotornot2 from [CRAN](https://CRAN.R-project.org) with:

``` r
install.packages("tweetbotornot2")
```

## Predict

### Use `predict_bot()` to use the built-in bot classifier

Enter screen names of Twitter users of interest and `predict_bot()` 
returns the estimated probability that one or more Twitter accounts is a bot.

```{r}
## pass screen names to predict function
predict_bot(c("MagicRealismBot", "netflix_bot", "rdpeng", "hspter"))
```

`predict_bot()` also accepts previously collected Twitter data (e.g., data returned by `rtweet::get_timelines()`)

```{r}
## estimate bot probabilities
twtdat <- rtweet::get_timelines(
  c(
    ## (these ones should be bots)
    "American__Voter",
    "MagicRealismBot", 
    "mitchhedbot",
    "rstats4ds", 
    "thinkpiecebot", 
    "tidyversetweets", 
    "newstarsbot",
    ## (these ones should be Nots)
    "AOC", 
    "kearneymw", 
    "kumailn", 
    "mindykaling", 
    "NateSilver538", 
    "realDonaldTrump", 
    "hspter",
    "rdpeng"),
  n = 200, check = FALSE)

## view output (order most likely to least like bot)
predict_bot(twtdat)[order(-prob_bot), ]
```

## Explain

### Use `explain_bot()` to see the contributions made by each feature in the model

Examine prediction contributions for features in the model

```{r}
## view top features in predictions of each user
explain_bot(twtdat)[feature %in% feature[1:10], .SD, on = "feature"][1:30, -1]
```


## Update

### Use `sample_via_twitter_lists()` to gather new users

`sample_via_twitter_lists()` leverages Twitter lists to snowball sample from a few users (input) to hundreds or even thousands of users (output). Use it to find and label "bot" and "not" (bot) Twitter accounts via snowball sampling

``` r
## find up to 10,000 accounts similar to these well-known Twitter bots
bots <- sample_via_twitter_lists(c("netflix_bot", "American__Voter", "UTLEGtracker", 
  "JVLast", "EndlessJeopardy", "PossumEveryHour", "MagicRealismBot", "factbot1"), 
  n = 10000)

## retrieve user and timeline information for each user
bots_tmls <- tweetbotornot_collect(bots)
```

### Use `preprocess_bot()` to prepare user timeline data for modeling

Extract and transform numeric features from the data

``` r
## wrangle, munge, aggregate data for modelling
bots_tmls <- preprocess_bot(twtdat)
```

### Use `tweetbotornot_update` to train the model on new data

``` r
## train model
new_model <- tweetbotornot_update(newdata)

## use updated model to get new predictions
predict_bot(new_model, c("netflix_bot", "mindykaling"))
```

## About Model

### Feature importance

The most influential features in the classifier

```{r, include=FALSE, eval=FALSE}
idsbot <- c("user_id", "screen_name", "bot")
xgboost::xgb.ggplot.importance(xgboost::xgb.importance(
  model = tweetbotornot_xgb_model,
  trees = 1:1000), measure = "Gain", top_n = 28) +
  ggplot2::scale_fill_viridis_d(begin= 0.05, end = 0.9) +
  dataviz::theme_mwk(12, "Avenir Next LT Pro") +
  ggplot2::coord_cartesian(ylim = c(0, 0.3)) +
  ggplot2::coord_flip(ylim = c(0, .12)) + 
  ggplot2::ggsave("man/figures/README-import.png", width = 9, height = 8,
    units = "in", dpi = 312)
```

![](man/figures/README-import.png)

### Feature contributions

How features contributed to predictions in the original training data:

```{r, include=FALSE, eval=FALSE}
.d <- tfse::read_RDS("../twbt/data-final-munged.rds")

png("man/figures/README-shap.png", width = 9, height = 8, units = "in", res = 312)
par(tcl = -0.175, bty = "n", xaxt = "s", yaxt = "s", col = "#aaaaaa")
cols <- viridis::viridis_pal(begin = 0.1, end = 0.9)(2)
suppressWarnings(
  xgboost::xgb.plot.shap(
    data = as.matrix(.d[, -(1:3)]),
    trees = 1:150,
    model = tweetbotornot_xgb_model,
    top_n = 36, n_col = 6,
    discrete_jitter = 0.15, span_loess = 0.35, col_loess = cols[1],
    col = cols[2],
    family = "Avenir Next LT Pro",
    cex.lab = 1.5,
    ylab = NA
  )
)
dev.off()
```

![](man/figures/README-shap.png)


